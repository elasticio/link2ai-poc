<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>About – Chatbot with AI</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" />
  <link rel="stylesheet" href="style.css" />
</head>
<nav class="navbar navbar-light bg-white mb-4">
  <div class="container">
    <a class="navbar-brand" href="index.html">Chatbot with AI</a>
    <a class="btn btn-outline-secondary" href="about.html">About</a>
  </div>
</nav>
<body class="bg-light">
  <div class="container py-4">
    <h2 class="mb-4">About This Chatbot</h2>

    <p>This page offers a comprehensive overview of a <strong>proof-of-concept chat application</strong> that integrates with AI governance services for AI-powered conversations and input validation.</p>

    <p>The application serves as a functional example of implementing <strong>secure chat interfaces</strong> with real-time AI responses and optional malicious content detection.</p>

    <p>The AI-powered bot simulates a <strong>sales support process for a coffee machine store</strong>. Users can interact naturally, and responses are generated in real time.</p>

    <p>The application provides optional input validation through AI governance service security features. Users can toggle validation using the <strong>"Validate Input"</strong> switch, which affects both the request payload and the user interface feedback.</p>

    <p>When validation is enabled, the system checks for <strong>prompt injections</strong> and flags unsafe content. If an injection attempt is detected, a message like <strong>"Prompt rejected. Malicious input detected by Link2AI ❌"</strong> is shown.</p>

    <a href="index.html" class="btn btn-primary mt-3">← Back to Chat</a>
  </div>
</body>
</html>
